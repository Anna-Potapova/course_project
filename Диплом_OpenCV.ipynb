{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ноутбук должен быть создан в среде tensorflow.\n",
    "Если её еще нет, то настроить среду можно в Anaconda Navigator следующим способом:\n",
    "-зайти в \"Environment\",\n",
    "-нажать \"Create\",\n",
    "-дать имя среде, например, \"tensorflow\",\n",
    "-нажать \"Apply\",\n",
    "-справа выбрать опцию \"Not installed\", подождать несколько минут, пока подгрузятся директории с названиями, содержащими \"tensorflow\",\n",
    "-выбрать \"tensorflow\"\n",
    "-перейти в \"Home\",\n",
    "-в блоке \"Jupyter\" нажать на \"Install\" и установить Jupyter notebook.\n",
    "\n",
    "Для работы камеры требуется запускать ноутбук локально, у себя на компьютере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.46-cp38-cp38-win_amd64.whl (33.5 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\baba_\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.46\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.3-cp38-cp38-win_amd64.whl (8.5 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\baba_\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\baba_\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\baba_\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in c:\\users\\baba_\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-win_amd64.whl (51 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.0.1-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3 pillow-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n",
    "import cv2\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "wget.download('https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PREDICT_EMOTION(tf.keras.Model):\n",
    "    def __init__(input_path):\n",
    "        \n",
    "        \"\"\"\n",
    "        input_path -- путь для загрузки весов модели\n",
    "        \"\"\"\n",
    "\n",
    "        model = load_model(input_path)\n",
    "        return model\n",
    "    \n",
    "    def predict_emotion(model, saving_output_path, loading_path, image_shape):\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        if not cam.isOpened():\n",
    "            print(\"Не удалось открыть камеру\")\n",
    "        else:\n",
    "            print(\"Камера запущена\")\n",
    "        \n",
    "        ret, frame = cam.read()\n",
    "        if ret == True:\n",
    "            plt.imshow(frame)\n",
    "        bgr_image = frame\n",
    "        bgr_image = cv2.resize(bgr_image, (image_shape, image_shape))\n",
    "        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "#saving_output_path и loading_path важно разделить, так как flow_from_directory (ниже) будет считывать фотографии\n",
    "#из папки более высокого уровня, пример:\n",
    "#saving_output_path=\"saved_images/images\", loading_path=\"saved_images\", где loading_path является родительской директорией для  saving_output_path       \n",
    "        face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        faces = face_detector.detectMultiScale(grayscale_image, 1.3, 5)\n",
    "        print(\"Найдено {} лицо/лиц\".format(len(faces)))\n",
    "        print(\"Массив faces: {}\".format(faces))\n",
    "        \n",
    "        one_face = faces[0]\n",
    "        x, y, w, h = one_face\n",
    "        face_boundingbox_bgr = bgr_image[y:y + h, x:x + w]\n",
    "        face_boundingbox_rgb = cv2.cvtColor(face_boundingbox_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        path = saving_output_path\n",
    "        cv2.imwrite(os.path.join(saving_output_path, 'loaded_image.jpg'), rgb_image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    #def read_frame():\n",
    "        #while(True):\n",
    "            #ret, frame = cam.read()\n",
    "            #cv2.imshow(\"facial emotion recognition\", frame)\n",
    "            \n",
    "            #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                #break\n",
    "                \n",
    "        image_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "        \n",
    "        loaded_image_generator_emotion = image_gen.flow_from_directory(\n",
    "            directory = loading_path,\n",
    "            target_size=(image_shape, image_shape))\n",
    "        \n",
    "        predicted_classes = model.predict_classes(loaded_image_generator_emotion)\n",
    "        classes_mapping = {0: 'anger', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happy', 5: 'neutral', 6: 'sad', 7: 'surprise', 8: 'uncertain'}\n",
    "        \n",
    "        path = saving_output_path\n",
    "        for i in predicted_classes:\n",
    "            emotion_text = str(classes_mapping[i])\n",
    "   \n",
    "            rgb_image = cv2.imread(os.path.join(saving_output_path, 'loaded_image.jpg'))\n",
    "            rgb_image_with_boundingbox = deepcopy(rgb_image)\n",
    "            rgb_image_with_boundingbox = cv2.rectangle(rgb_image_with_boundingbox, (y, x), (y + h, x + w), (0,255,0), 3)\n",
    "            rgb_image_with_boundingbox_and_text = deepcopy(rgb_image_with_boundingbox)\n",
    "            rgb_image_with_boundingbox_and_text = cv2.putText(rgb_image_with_boundingbox_and_text, emotion_text, (y, x - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.imshow(rgb_image_with_boundingbox_and_text)\n",
    "            plt.title(\"Predicted emotion:\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emotion = PREDICT_EMOTION.__init__(\"Диплом/Submission_2_29.12.20/model_emotion/checkpoint_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_EMOTION.predict_emotion(model_emotion, saving_output_path=\"saved_images/images\", loading_path=\"saved_images\", image_shape=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
